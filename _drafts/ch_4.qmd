---
title: "Chapter 4"
subtitle: "Using sensing data to predict opioid lapse risk in a national sample of patients with opioid use disorder"
format: html
date: last-modified
bibliography: references.bib
---

# Introduction

Studies show high agreement between recent (i.e., 1-4 days) self-report and biological markers (i.e., urine, saliva, hair) of drug use [@bharatAgreementSelfreportedIllicit2023]. This suggests people may be willing to report illicit substance use behaviors. 

However, it is unclear if people in recovery from substance use disorders, other than alcohol, can sustain long-term adherence (e.g., one year or more) needed for a recovery monitoring support system that uses self-report data. It is also unclear whether people in recovery can or are willing to accurately report other risk information. 

Additionally, models that only use self-report information could 

- More features would improve personalization

This project will use daily surveys and sensed geolocation for up to one year from people in recovery for opioid use disorder.


# Specific Aims

In this study, we will take advantage of an existing dataset of personal sensing data (1X daily EMA and geolocation) and opioid lapse reports from a national sample of people with opioid use disorder to predict immediate (i.e., in the next 24 hours) lapses back to opioid use. 

Specifically, we will:

**1. Evaluate the performance (auROC) of a machine learning model that predicts opioid lapses from geolocation and 1X daily EMA.** This aim will allow us to determine whether lapse prediction models can be generalized to other drugs beyond alcohol. Notably, a successful model will demonstrate that lapse prediction can be done with a drug where its use is illegal and people may be less willing to provide information about lapses and risk factors. 

**2. Assess model fairness in performance across important subgroups with known disparities in substance use treatment access and/or outcomes - race/ethnicity (not White vs. non-Hispanic White), income (below poverty vs. above poverty), sex at birth (female vs. male), and geographic location (rural vs. urban).** These data offer more diversity with regard to race/ethnicity, income, and geographic location. This aim will allow us to determine if improving the quality of the training data with respect to diversity is sufficient to address issues of fairness.  

**3. Describe the relative importance of features on model performance.** Model features will be derived from two complementary sensing methods: 1X daily EMA and continuous geolocation data. Geolocation sensing, a passive sensing method, could compliment EMA well. It could provide insight into information difficult to measure with self-report (e.g., the amount of time spent in risky locations, or changes in routine that could indicate life stressors) or that would add additional burden by increasing the number of questions on the EMA. Furthermore, by adding more data sources gives us more features and that could mean better personalization of predictions and recommendations for more people. This aim will help determine whether a sufficient number of unique important features emerge from these data.

# Methods

## Participants

## Procedure

## Measures

### Individual Characteristics

### Daily Surveys

### Monthly Surveys

### Sensed Geolocation

## Planned Data Analyses

### Labels

### Feature Engineering

### Model Training and Evaluation