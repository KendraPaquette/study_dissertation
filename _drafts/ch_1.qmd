---
title: "Chapter 1"
format: html
date: last-modified
bibliography: references.bib
---

# Introduction

## Substance Use Disorders

In 2023, over 46 million U.S. adults had a substance use disorder in the past year [@substanceabuseandmentalhealthservicesadministration2023NSDUHDetailed]. This is nearly 18% of the U.S. adult population.

Substance use disorders are associated with high rates of morbidity and mortality. Opioid overdose rates remain high and continue to increase each year [@IncreasesDrugOpioid; @friedmanTrendsDrugOverdose2022]. Excessive alcohol use is a leading preventable cause of death, with the majority of these deaths caused by alcohol-attributed cancer, heart problems and stroke, and liver cirrhosis [@ARDIAlcoholAttributableDeaths]. Additionally, alcohol-impaired driving accounts for over 30% of traffic fatalities each year [@unitedstatesdepartmentoftransportation2024].  

The economic cost of substance use disorders is substantial. In 2016 the economic cost associated with substance use disorders was estimated to exceed \$442 billion in lost productivity, health care expenses, law enforcement, and other criminal justice costs [@substanceabuseandmentalhealthservicesadministrationusFacingAddictionAmerica2016]. When also accounting for costs associated with loss of life and reduced quality of life, one research group estimated that in 2017 the cost of opioid use disorder alone exceeded \$1 trillion [@florenceEconomicBurdenOpioid2021]. 

## Treatment

Substance use disorders are chronic conditions, characterized by high relapse rates. [@mclellanDrugDependenceChronic2000; @dennisManagingAddictionChronic2007], substantial co-morbidity with other physical and mental health problems [@substanceabuseandmentalhealthservicesadministration2023NSDUHDetailed; @dennisManagingAddictionChronic2007], and an increased risk of mortality [@hedegaardDrugOverdoseDeaths; @centersfordiseasecontrolandpreventioncdcAnnualAverageUnited].  

Initial treatments, including medication (e.g., methadone, buprenorphine, and naltrexone for opioid use disorder and acamprosate, disulfiram, and naltrexone for alcohol use disorder) and evidenced-based psychosocial treatments (e.g., relapse prevention [@marlattRelapsePreventionMaintenance1985; @marlattRelapsePreventionSecond2007], mindfulness-based relapse prevention [@bowenMindfulnessBasedRelapsePrevention2021], and cognitive-behavioral therapy [@lieseCognitiveBehavioralTherapyAddictive2022]), are efficacious for symptom stabilization and harm reduction when provided. Unfortunately, too often individuals do not receive treatment [@substanceabuseandmentalhealthservicesadministration2023NSDUHDetailed]. 

Equally concerning, is the lack of continuing support and care provided to individuals after completing initial treatment [@stanojlovicTargetingBarriersSubstance2021; @sociasAdoptingCascadeCare2016]. Continuing care, including on-going monitoring, tailored adjustments to lifestyle and behaviors over time, and when necessary re-engagement with more intensive treatment, is the gold standard for treating chronic conditions, like diabetes, hypertension, and asthma. Similarly, substance use treatment has been shown to be most effective when care is prescribed over longer durations and involves active efforts to keep patients engaged in their recovery [@mckayImpactContinuingCare2021]. Yet, for reasons including cost and insurance reimbursement issues, lack of collaborative provider teams, passive referral processes, geographic barriers to accessing services, patient dropout, and changes in the patientâ€™s clinical needs over time [@dennisManagingAddictionChronic2007; @taiTreatmentSubstanceUse2013; @mckayImpactContinuingCare2021; @stanojlovicTargetingBarriersSubstance2021], our current treatment system for substance use disorders does not not appear to have the capacity for long-term clinician-delivered care. This leaves individuals left to determine on their own "How can I best support my recovery today?"

This type of self-monitoring can be extremely difficult. The risk factors that precede lapse (i.e., single instances of goal-inconsistent substance use) and full relapse back to harmful use during recovery are individualized, numerous, dynamic and interactive [@witkiewitzModelingComplexityPosttreatment2007; @brandonRelapseRelapsePrevention2007]. Therefore, the optimal supports to address these risk factors and encourage continued, successful recovery vary both across individuals and within an individual over time. 

<!--could make the point then that although people arent receiving initial treatment, we  have them ready but for continuing care, we likely need to develop an entirely new system of care.--><!--KW: this is interesting, keeping this comment in for now.-->

## Recovery Monitoring and Support System

An algorithm-guided recovery monitoring and support system could help patients monitor their current and future risk of lapse and make adjustments in their activities and supports to meet their recovery goals after initial treatment. Such a tool could offer personalized, adaptive recommendations aligned with evidenced-based care (i.e., relapse prevention model) and prompt individuals to engage with support at times of high risk. For example, individuals could receive daily messages about changes in their lapse risk and receive personalized recommendations based on top features contributing to their risk, like an urge surfing recommendation for someone with strong cravings. Moreover, it would provide a scalable option for long-term monitoring and support to address the substantial unmet need for continuing care for substance use disorders. 

For such a system to exist, at least three pre-requisites must be met^[Of course, these are not the only things needed for a successful recovery monitoring support system. For example, people must be willing and able to provide sensing data and the system must able to provide risk-relevant feedback to the individual in a useful and clinically helpful way. While important, these questions are outside the scope of the current proposal (see @wyantAcceptabilityPersonalSensing2023 and @wyantOptimizingMessageComponentsinprep).]. One, the system must be able to collect a rich and densely sampled source (or sources) of risk-relevant data. Two, the system must have access to a model that can predict substance use with high performance and temporal precision and have interpretable model inputs for support recommendations to be mapped onto. Three, the model must perform fairly. The accuracy of the predictions and usefulness and relevance of the recommendations should be similar for everyone. Advances in both smartphone sensing [@mohrPersonalSensingUnderstanding2017] and machine learning [@hastieElementsStatisticalLearning2009] now make this possible.

Smartphone sensing approaches (e.g., ecological momentary assessment [EMA], geolocation sensing) can provide the frequent, longitudinal measurement of proximal risk factors that is necessary for prediction of future lapses with high temporal precision. 

Machine learning models can handle the high dimensional feature sets that may result from feature engineering densely sampled raw EMA over time. They can also accommodate non-linear and interactive relationships between features and lapse probability.  And methods from interpretable machine learning can be used to understand which risk features contribute most strongly to a lapse prediction for a specific individual at a specific moment in time.

## Aims of this proposal

This dissertation proposal describes a program of research that seeks to develop an algorithm to be used in a recovery monitoring and support system. Two projects (chapters 2 and 3) are completed and two projects (chapters 3 and 4) are planned and under development. These projects are explained more below:

**Chapter 2:** Machine learning models for temporally precise lapse prediction in alcohol use disorder 

This project demonstrated that 4x daily EMA could be used to build temporally precise machine learning models to predict alcohol lapses. Specifically, we built three models to predict the probability of an alcohol lapse in the next week, day, and hour. 

Our models performed exceptionally well with median posterior probabilities for area under the ROC curve (auROC) of .90, .91, and .93 for predicting lapse probabilities into the next week, day, and hour, respectively. We calculated additional performance metrics for using a binary classification of lapse or no lapse at a decision threshold that maximized sensitivity and specificity. All three models performed generally well with metrics of sensitivity, specificity, balanced accuracy, and negative positive predictive value all > .80. 

Positive predictive value (PPV), however, was moderate at best and dramatically declined as the prediction window width became more narrow: .63 (week), .30 (day), .02 (hour). PPV represents the proportion of predicted lapses that are true lapses. For example, an observation labeled as a lapse by a model with .30 PPV has only a 30% likelihood of being a true lapse. While PPV can be increased by raising the decision threshold (albeit with a cost to sensitivity), we have come to recognize that categorical lapse prediction may not be optimal for our big picture goal - developing an algorithm to be used in a recovery monitoring and support system. Telling individuals the model predicts they will lapse in the next day, likely offers no clinical benefit. This feedback could also have harmful consequences, such as inducing abstinence violation effects or other maladaptive cognitive processes. As a result, future studies included in this proposal will focus solely on evaluating the quantitative predicted probabilities of lapse risk, as opposed to binary classification. 

In this study we also demonstrated it is possible to understand important features overall for a model (i.e., across all observations for all participants) and important features for an individual prediction (i.e., for a single individual at a specific moment). We found on average past use, craving, and abstinence self-efficacy were the most important features affecting predicted probability scores across the three models. We also saw a wide range of individual feature importance values across all people and all days, suggesting that even features with relative low overall importance were still clinically important for some people at some moments.

These findings suggest that it is feasible to identify periods of high lapse risk at varying levels of temporal precision and extract important risk features. If embedded in a recovery monitoring and support system, output from models that predict immediate lapses, like these, could be used to provide individuals critical information about their immediate risk of lapse. Daily (or more or less frequent) messages could be sent to individuals that relay information about changes in their risk and make supportive recommendations for immediate action based on the top features contributing to their risk. For example, recommending a coping with craving activity for someone experiencing strong cravings, recommending a guided relaxation video for someone reporting recent stressful events, or encouraging individuals to reflect on recent past successes or reasons for choosing abstinence or moderation when reported self-efficacy is low. Importantly, this assumes that the recommendations can be implemented immediately. Thus, the individual has already likely learned the skill and it is not contingent on scheduling or other people.   

However, often the most clinically appropriate support recommendation takes time to set up. Scheduling positive or pleasant activities, increasing social engagement, or attending a peer-led recovery meeting may require days or weeks to implement. In these cases, patients would benefit from advanced warning about changes in their risk. This advanced warning could be obtained by lagging lapse probability predictions further into the future (e.g., predicting the probability of a lapse in a 24-hour window that begins two weeks in the future). 

Finally, in this study, we failed to assess model fairness. In recent years, the machine learning field has begun to understand the critical importance of evaluating model fairness when algorithms are used to inform important decisions (e.g., healthcare services offered, eligibility for loans, early parole). Algorithms that perform favorably for only a single majority group could widen existing disparities in access to resources and important clinical outcomes [@veinotGoodIntentionsAre2018]. Future studies included in this proposal will explicitly evaluate model performance parity across important subgroups. 


**Chapter 3:**  Lagged predictions of next day alcohol lapse risk for personalized and adaptive continuing care support

This project showed that the same 4x daily EMA could be used to predict alcohol use occurring within a 24-hour window up to two weeks into the future. We considered several meaningful lags between the prediction timepoint and start of the prediction window: 1 day, 3 days, 1 week, and 2 weeks. These models with lagged prediction windows can be used to provide personalized support recommendations with the added benefit of advanced warning. Thus, giving an individual extra time to implement the recommendation.

Model performance decreased as the start of the prediction window was lagged further from the prediction timepoint with median posterior probabilities for auROC of .88 (1-day lag), .87 (3-day lag), .86 (1-week lag), and .84 (2-week lag). This decrease in performance is not surprising given what we know about prediction and alcohol lapse. Many important lapse risk factors are fluctuating processes that can change day-by-day, if not more frequently. As lag times increase, features become less proximal to the start of the prediction window. Still, auROCs of .80 and higher are generally considered to indicate good performance and the benefit of advanced notice of lapse risk likely outweighs the cost to performance.

In this study, we also assessed model fairness by comparing model performance (posterior probability for auROC) across important subgroups with known disparities in substance use treatment access and/or outcomes - race/ethnicity (not White vs. non-Hispanic White), income (below poverty vs. above poverty), and sex at birth (female vs. male). There was strong evidence that our models performed better for individuals who were non-Hispanic White, male, and had a personal income above the Federal poverty line.

The relative ordering of important features remained somewhat consistent across the models. Past use, future efficacy, and craving were the top three features for all models. However on average these features became less important as model predictions lagged further into the future, consistent with their lower performance. As with the previous study, we found a wide range of individual importance values for features across the models.

These results are promising, however, several limitations exist. Most notably was a lack of fairness in the performance of our models among subgroups. The largest contributing factor is likely the lack of diversity in our training data. Even with our coarse dichotomous grouping of race we only had 20 participants in the not White group (compared to 131 in the White group). We also saw a similar pattern in our income groups (49 people in the below poverty group compared to 102 people in the above poverty group).

However, we had equal representation of men and women and still found our models performed better for men. We chose our 9 EMA items based on the extant relapse risk literature. Historically women were excluded from early substance use research due to their childbearing potential. It is possible that these constructs more precisely describe relapse risk factors for men than for women. 

One solution, would be to add additional EMA items to the daily surveys in hopes to capture important risk factors for women. This however, would quickly increase the burden of our surveys. EMA acceptability studies suggest that longer surveys, but not more frequent prompts, promote increased perceived burden and compromised data quantity and quality [@eiseleEffectsSamplingFrequency2020]. Therefore, supplementing EMA with another lower burden sensing method may be preferred. Additionally, passive sensing data may be well-suited for data-driven (bottom-up) feature engineering approaches. Compared to traditional, theory-driven (top-down) methods, data-driven features can identify patterns and characteristics predictive of lapse in specific groups and reduce potential bias in features by minimizing researcher involvement.
    
A few other limitations were inherent in the data set. First, was the length of participation. As participants only provided data for up to three months, we were limited by how far into the future we could lag predictions. It is likely that even more advanced warning (e.g., 1 month) would be helpful for implementing more intensive supports (e.g., re-engagement with clinician-delivered care). Second, the results presented in chapters 2-3 focus on alcohol lapse prediction. Alcohol differs from other substances in several ways. It is legal and generally viewed to be socially acceptable (e.g., it is often integrated into celebrations and social gatherings). As a result, individuals who use other substances (e.g., opioids) may face more stigma and be less willing to report substance use and risk information. Therefore, it is not clear that similar prediction models will perform as well. 


**Chapter 4:** Using sensing data to predict opioid lapse risk in a national sample of patients with opioid use disorder

In this study, we will take advantage of an existing dataset of personal sensing data (1X daily EMA and geolocation) and opioid lapse reports from a national sample of people with opioid use disorder to predict immediate (i.e., in the next 24 hours) lapses back to opioid use. 

This study will allow us to generalize lapse prediction algorithms to other drugs beyond alcohol. Notably, a successful model will demonstrate that lapse prediction can be done with a drug where its use is illegal and people may be less willing to provide information about lapses and risk factors. 
    
These data also offer more diversity with regard to race/ethnicity and income. This will allow us to determine if improving the quality of the training data with respect to diversity is sufficient to address issues of fairness. These data also offer diversity across geographic location (e.g., rural vs. urban), likely another important factor in evaluating fairness. 

In this proposed study, model features will be derived from two complementary sensing methods: 1X daily EMA and continuous geolocation data. Geolocation sensing, a passive sensing method, could compliment EMA well. It could provide insight into information difficult to measure with self-report (e.g., the amount of time spent in risky locations, or changes in routine that could indicate life stressors) or that would add additional burden by increasing the number of questions on the EMA. Furthermore, by adding more data sources gives us more features and that could mean better personalization of predictions and recommendations for more people.

Participants provided data for up to 12 months. This extended window of recovery (12 months vs. 3 months) is critical for evaluating the value of an algorithm intended for ongoing continuing care support and understanding how lapse risk evolves as people progress in their recovery (i.e., past 3 months). Unfortunately, our ability to address explanatory questions about the time course of lapse risk, and how individuals might cluster on different recovery trajectories is limited with traditional machine learning methods. These methods do not capture the repeated nature of sensing data. Each lapse prediction is treated as a new independent observation. We can account for the repeated observations in our sensing data by engineering features that capture individual changes over time to produce unbiased and precise estimates of predictive performance. However, more traditional time series models are better suited for understanding the temporal dynamics of lapse risk over long periods of recovery.

The longer duration of participation also provides the opportunity to experiment with lagged prediction windows further than two weeks into the future (i.e., 1 month). However, in a machine learning framework, different models must be built to predict lapses at varying times in the future. For example, a recovery monitoring support system that detects both immediate lapse risk (i.e., in the next 24 hours) and future lapse risk (i.e, in the next 2 weeks and in the next month) would need three models. This approach is time consuming, cumbersome, and still only provides coarse understanding of time-course. Therefore, this study will only predict immediate lapse risk.


**Chapter 5:** State-space models for idiographic risk monitoring and recovery support recommendations

In this study, we propose Hierarchical Bayesian state-space models as an alternative approach for prediction models. State-space models model measured inputs (e.g., ema responses, time spent in risky locations, time spent at home) and outputs (i.e., lapse or no lapse) from time series data with latent states. The hierarchical nature, will allow us to better use and understand time-varying information. State-space models explicitly model how the latent state of an individual's lapse risk evolves over time. These states can then be extracted from the model and used for understanding lapse risk and improving recovery support recommendations. 
    
Given the heterogeneity in lapse risk and the complex interactions between environment and individual differences, a time series model that use an individual's own data to make future predictions may perform better than models trained at the group-level. Therefore, we will build an individual model for each participant using their own data. Although our immediate lapse risk models have been performing quite well, individual models could improve performance for our lagged prediction models. Individual models also may help mitigate issues of unfairness, as the model will weigh the individual's own data more heavily than group level estimates.

Additionally, time series models could potentially improve the efficiency and performance of lagged prediction models. A single model can be used to predict a lapse at any point in the future, eliminating the need for multiple models for predicting immediate and future lapse risk. 

Therefore, in this study, we will evaluate the performance and fairness of a state-space model approach for opioid lapse risk prediction using the EMA and geolocation data set introduced in Chapter 4. We will evaluate both immediate (i.e., in the next 24 hours) and future (i.e., next 2 weeks and next 1 month) lapse risk. We will also assess the usability of latent states as intervenable targets for recommendations. 
  

  
    
